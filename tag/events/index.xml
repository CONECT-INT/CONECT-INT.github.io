<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>events | CONECT | Computational Neuroscience Center @ INT</title><link>https://conect-int.github.io/tag/events/</link><atom:link href="https://conect-int.github.io/tag/events/index.xml" rel="self" type="application/rss+xml"/><description>events</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© The [CONECT group](https://conect-int.github.io/people/)</copyright><lastBuildDate>Fri, 04 Mar 2022 14:30:00 +0000</lastBuildDate><image><url>https://conect-int.github.io/images/icon_hu7e281b73228ab43411ccffce0f285528_35679_512x512_fill_lanczos_center_3.png</url><title>events</title><link>https://conect-int.github.io/tag/events/</link></image><item><title>2022-03-04 : INT Seminar - "Unifying Different Psychometric Methods : Theory and Experiment" (Jonathan Vacher)</title><link>https://conect-int.github.io/event/2022-03-04_seminaire-jonathan-vacher/</link><pubDate>Fri, 04 Mar 2022 14:30:00 +0000</pubDate><guid>https://conect-int.github.io/event/2022-03-04_seminaire-jonathan-vacher/</guid><description>&lt;p>During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href="https://jonathanvacher.github.io/" target="_blank" rel="noopener">Jonathan Vacher&lt;/a> will present his recent work on &amp;ldquo;&lt;strong>Unifying Different Psychometric Methods : Theory and Experiment&lt;/strong>&amp;quot;:&lt;/p>
&lt;blockquote>
&lt;p>The two-alternative forced choice (2AFC) paradigm is one of the main methods used to measure perceptual thresholds and biases. Measurements from a 2AFC experiment can be modelled using signal detection theory (SDT) from which the psychometric function can be derived theoretically. Recent efforts to combine SDT with Bayesian probabilities has linked thresholds and biases to hypothesized prior knowledge and optimal encoding/decoding [1]. From another perspective, the maximum likelihood difference scaling (MLDS) paradigm is a more recent method that allows the experimenter to estimate a perceptual scale that links a physical property to a psychological dimension [2]. Such a perceptual scale is obtained from the comparison of relative differences between pairs of stimuli. Here again, the underlying model can be understood in terms of SDT and Bayesian probabilities. However, no comparison between MLDS and 2AFC measurements has been performed yet. Here, we introduce the theory that unifies those measurements and we present some preliminary experimental results. In this context, we further explore how MLDS measurements could help to understand the perception of more complex textures generated from the statistic of deep neural network features [3].&lt;/p>
&lt;/blockquote>
&lt;p>[1] Wei, X. X., &amp;amp; Stocker, A. A. (2017). Lawful relation between perceptual bias and discriminability. Proceedings of the National Academy of Sciences, 114(38), 10244-10249.&lt;/p>
&lt;p>[2] Maloney, L. T., &amp;amp; Yang, J. N. (2003). Maximum likelihood difference scaling. Journal of Vision, 3(8):5, 573-585.&lt;/p>
&lt;p>[3] Vacher, J. &amp;amp; Davila, A., Kohn, A. &amp;amp; Coen-Cagli, R. (2021). Texture Interpolation for Probing Visual Perception. Advances in Neural Information Processing Systems, 33.&lt;/p>
&lt;div class="alert alert-note">
&lt;div>
Dr. &lt;a href="https://jonathanvacher.github.io/">Jonathan Vacher&lt;/a> was a student at École Normale Supérieure de Cachan (now &lt;a href="http://www.ens-paris-saclay.fr/en">Saclay&lt;/a>) where he pursued a degree in mathematics and applied mathematics. He completed his bachelor&amp;rsquo;s and master&amp;rsquo;s degree with a specialty in computational imaging and machine learning (&lt;a href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/">Master MVA&lt;/a>). He started a multidisciplinary PhD in mathematics (&lt;a href="http://www.dauphine.fr/en/research/research-centers/ceremade-umr-7534.html">Paris Dauphine University, CEREMADE)&lt;/a> and neuroscience (&lt;a href="https://neuropsi.cnrs.fr/fr/icn/">CNRS, UNIC&lt;/a>) under the supervision of &lt;a href="http://www.gpeyre.com/">Gabriel Peyré&lt;/a> and &lt;a href="https://www.unic.cnrs-gif.fr/people/cyril_monier/">Cyril Monier&lt;/a>. Then, Jonathan was a postdoc at Albert Einstein College of Medicine in New-York between 2017 and 2020 while initiating a collaboration with Pascal Mamassian from the Laboratoire des Systèmes Perceptifs ()École Normale Supérieure de Paris) where he is currently a postdoc.
&lt;/div>
&lt;/div></description></item><item><title>2022-03-04 : CONECT Seminar - "Explainable AI for computational auditory neurosciences" (Etienne Thoret)</title><link>https://conect-int.github.io/event/2022-02-24_seminaire-etienne-thoret/</link><pubDate>Thu, 24 Feb 2022 14:00:00 +0000</pubDate><guid>https://conect-int.github.io/event/2022-02-24_seminaire-etienne-thoret/</guid><description>&lt;p>Etienne Thoret (ILCB/PRISM/LIS/AMU) kindly accepted to present his research project during our novel series of CONECT-core © seminars (=seminars open to all but focused on the core theoretical scientific questions of the CONECT members):&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Explainable AI for computational auditory neurosciences&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>Machine learning and deep neural networks have been raised as compelling models to simulate a broad range of tasks on signals: from classification of sound events to the prediction of human physiological state from electrophysiological data. But what do we really understand about these models and how do they process the information they have been trained to process? As users, we often use them as tools without precisely understanding their mechanistic and representational underpinnings. In this talk, I&amp;rsquo;ll present recent works on how we can take part of these computational systems to answer fundamental research mysteries on auditory perception, speech production and cerebral processing. Beyond acoustics and sound perception, these techniques can find applications for the modeling of a variety of systems, including computational vision in robotics, haptics and clinical applications.&lt;/p>
&lt;/blockquote></description></item><item><title>2021-12-10 : CONECT talk - "Sequence anticipation and STDP emerge from a voltage-based predictive learning rule" (Matteo Saponati)</title><link>https://conect-int.github.io/event/2021-12-10_seminaire-matteo-saponati/</link><pubDate>Fri, 10 Dec 2021 11:00:00 +0000</pubDate><guid>https://conect-int.github.io/event/2021-12-10_seminaire-matteo-saponati/</guid><description>&lt;p>During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href="https://github.com/matteosaponati" target="_blank" rel="noopener">Matteo Saponati&lt;/a>, will present his recent work showing that &amp;ldquo;&lt;strong>Sequence anticipation and STDP emerge from a voltage-based predictive learning rule&lt;/strong>&amp;quot;:&lt;/p>
&lt;blockquote>
&lt;p>Intelligent behavior depends on the brain’s ability to anticipate future events. However, the learning rules that enable neurons to predict and fire ahead of sensory inputs remain largely unknown. We propose a plasticity rule based on predictive processing, where the neuron learns a low-rank model of the synaptic input dynamics in its membrane potential. Neurons thereby amplify those synapses that maximally predict other synaptic inputs based on their temporal relations, which provide a solution to an optimization problem that can be implemented at the single-neuron level using only local information. Consequently, neurons learn sequences over long timescales and shift their spikes towards the first inputs in a sequence. We show that this mechanism can explain the development of anticipatory motion signaling and recall in the visual system. Furthermore, we demonstrate that the learning rule gives rise to several experimentally observed STDP (spike-timing-dependent plasticity) mechanisms. These findings suggest prediction as a guiding principle to orchestrate learning and synaptic plasticity in single neurons.
&lt;a href="https://www.biorxiv.org/content/10.1101/2021.10.31.466667v1" target="_blank" rel="noopener">https://www.biorxiv.org/content/10.1101/2021.10.31.466667v1&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>when: Friday 10th of December at 11am&lt;/li>
&lt;li>where: Salle Laurent Vinay at the &lt;a href="https://www.int.univ-amu.fr/contact" target="_blank" rel="noopener">Institute of Neurosciences Timone&lt;/a>.&lt;/li>
&lt;/ul>
&lt;div class="alert alert-note">
&lt;div>
&lt;a href="https://github.com/matteosaponati">Matteo Saponati&lt;/a> is a PhD candidate at &lt;a href="https://www.esi-frankfurt.de/research/vinck-lab/">Ernst Strüngmann Institute (ESI) for Neuroscience - IMPRS for Neural Circuits&lt;/a>.
&lt;/div>
&lt;/div></description></item><item><title>2020-09-11 : CONECT talk - "Feedforward and feedback processes in visual recognition" (T Serre)</title><link>https://conect-int.github.io/event/2020-09-11_seminaire-thomas-serre/</link><pubDate>Fri, 11 Sep 2020 14:00:00 +0000</pubDate><guid>https://conect-int.github.io/event/2020-09-11_seminaire-thomas-serre/</guid><description>&lt;p>During a seminar at the Institute of Neurosciences Timone in Marseille, &lt;a href="http://serre-lab.clps.brown.edu/" target="_blank" rel="noopener">Thomas Serre&lt;/a> will present his recent work on &amp;ldquo;Feedforward and feedback processes in visual recognition&amp;rdquo;:&lt;/p>
&lt;blockquote>
&lt;p>Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching – and sometimes even surpassing – human accuracy on a variety of visual recognition tasks. In this talk, however, I will show that these neural networks and their recent extensions exhibit a limited ability to solve seemingly simple visual reasoning problems involving incremental grouping, similarity, and spatial relation judgments. Our group has developed a recurrent network model of classical and extra-classical receptive fields that is constrained by the anatomy and physiology of the visual cortex. The model was shown to account for diverse visual illusions providing computational evidence for a novel canonical circuit that is shared across visual modalities. I will show that this computational neuroscience model can be turned into a modern end-to-end trainable deep recurrent network architecture that addresses some of the shortcomings exhibited by state-of-the-art feedforward networks for solving complex visual reasoning tasks. This suggests that neuroscience may contribute powerful new ideas and approaches to computer science and artificial intelligence.&lt;/p>
&lt;/blockquote>
&lt;div class="alert alert-note">
&lt;div>
Dr. &lt;a href="http://serre-lab.clps.brown.edu/">Thomas Serre&lt;/a> is an Associate Professor in Cognitive Linguistic &amp;amp; Psychological Sciences and an affiliate of the Carney Institute for Brain Science at Brown University. He received a Ph.D. in Neuroscience from MIT in 2006 and an MSc in EECS from Télécom Bretagne (France) in 2000. His research seeks to understand the neural computations supporting visual perception and has been featured in the BBC series “Visions from the Future” and other news articles (The Economist, New Scientist, Scientific American, IEEE Computing in Science and Technology, Technology Review and Slashdot). Dr. Serre is the Faculty Director of the Center for Computation and Visualization and the Associate Director of the Initiative for Computation in Brain and Mind at Brown University. He also holds an International Chair in AI within the Artificial and Natural Intelligence Toulouse Institute (France). Dr. Serre has served as an area chair and a senior program committee member for top-tier machine learning and computer vision conferences including AAAI, CVPR, and NeurIPS. He is currently serving as a domain expert for IARPA’s Machine Intelligence from Cortical Networks (MICrONS) program and as a scientific advisor for Vium, Inc. He was the recipient of an NSF Early Career Award as well as DARPA’s Young Faculty Award and Director’s Award.
&lt;/div>
&lt;/div></description></item></channel></rss>